{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f35eed56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Zainr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Zainr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Zainr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import markovify\n",
    "from markovify.text import ParamError \n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "from newsapi import NewsApiClient\n",
    "import praw\n",
    "from pytrends.request import TrendReq\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from TTS.api import TTS\n",
    "import IPython.display as ipd\n",
    "tts = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\", progress_bar=False, gpu=False)\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"config.env\")\n",
    "\n",
    "NEWSAPI_KEY      = os.getenv(\"NEWSAPI_KEY\")\n",
    "REDDIT_ID        = os.getenv(\"REDDIT_CLIENT_ID\")\n",
    "REDDIT_SECRET    = os.getenv(\"REDDIT_CLIENT_SECRET\")\n",
    "REDDIT_AGENT     = os.getenv(\"REDDIT_USER_AGENT\")\n",
    "\n",
    "newsapi = NewsApiClient(api_key=NEWSAPI_KEY)\n",
    "reddit  = praw.Reddit(client_id=REDDIT_ID,\n",
    "                      client_secret=REDDIT_SECRET,\n",
    "                      user_agent=REDDIT_AGENT)\n",
    "pytrends = TrendReq()\n",
    "\n",
    "from uuid import uuid4\n",
    "import gradio as gr\n",
    "import json\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b6dfe",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f1a3c5",
   "metadata": {},
   "source": [
    "### Gutenberg Corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "711c0720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gutenberg corpus length: 520886 characters\n"
     ]
    }
   ],
   "source": [
    "with open(\"fairy_tales.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "start = text.find(\"*** START OF THE PROJECT GUTENBERG EBOOK GRIMMS' FAIRY TALES ***\")\n",
    "end   = text.find(\"*** END OF THE PROJECT GUTENBERG EBOOK GRIMMS' FAIRY TALES ***\")\n",
    "corpus_gutenberg = text[start:end]\n",
    "\n",
    "print(\"Gutenberg corpus length:\", len(corpus_gutenberg), \"characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f810de",
   "metadata": {},
   "source": [
    "### HuggingFace Gryphe ChatGPT-4o Writing Prompts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d793cbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared Gryphe corpus with 3741 entries, using first 5000.\n",
      "Sample:\n",
      " The smell in the kitchen was somewhere between charred wood and sulfur, a sharp, acrid tang that set the back of Mina's throat on fire. That was the first indication something had gone terribly, terribly wrong.\n",
      "\n",
      "She flipped frantically through the pages of her grandma’s old cookbook, the fragile, yellowed edges crumbling between her fingers as she scanned for something—anything—that could explain the colossal, horned creature standing in the middle of her kitchen. Flour dust still hung in the ai\n"
     ]
    }
   ],
   "source": [
    "ds_gryphe = load_dataset(\"Gryphe/ChatGPT-4o-Writing-Prompts\", split=\"train\")\n",
    "\n",
    "texts_gryphe = []\n",
    "for row in ds_gryphe:\n",
    "    msgs = row[\"conversations\"]\n",
    "\n",
    "    human = next((m[\"value\"] for m in msgs if m[\"from\"] == \"human\"), \"\")\n",
    "    gpt   = next((m[\"value\"] for m in msgs if m[\"from\"] == \"gpt\"), \"\")\n",
    "    if not gpt:\n",
    "        continue\n",
    "\n",
    "    include_human = False\n",
    "    combined = (human + \"\\n\\n\" + gpt) if include_human else gpt\n",
    "    texts_gryphe.append(combined.strip())\n",
    "\n",
    "corpus_gryphe = \"\\n\".join(texts_gryphe[:5000])\n",
    "print(f\"Prepared Gryphe corpus with {len(texts_gryphe)} entries, using first 5000.\")\n",
    "print(\"Sample:\\n\", corpus_gryphe[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1968bc",
   "metadata": {},
   "source": [
    "### Kaggle WritingPrompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49e2799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000 samples from 'writingprompts/train' (total chars: 15034991)\n",
      "Example snippet:\n",
      " [ WP ] You 've finally managed to discover the secret to immortality . Suddenly , Death appears before you , hands you a business card , and says , `` When you realize living forever sucks , call this number , I 've got a job offer for you . '' So many times have I walked on ruins , the remainings o …\n"
     ]
    }
   ],
   "source": [
    "def load_kaggle_corpus(split=\"train\", max_samples=5000, max_tokens=1000, base_path=\"writingprompts\"):\n",
    "    \"\"\"\n",
    "    Load Kaggle Writing Prompts split (train/test/valid) from the given folder,\n",
    "    combine source + target per line, truncate to max_tokens tokens,\n",
    "    and return up to max_samples combined entries.\n",
    "    \"\"\"\n",
    "    src_path = os.path.join(base_path, f\"{split}.wp_source\")\n",
    "    tgt_path = os.path.join(base_path, f\"{split}.wp_target\")\n",
    "    texts = []\n",
    "    with open(src_path, \"r\", encoding=\"utf-8\") as src_f, \\\n",
    "         open(tgt_path, \"r\", encoding=\"utf-8\") as tgt_f:\n",
    "        for i, (src, tgt) in enumerate(zip(src_f, tgt_f)):\n",
    "            if i >= max_samples:\n",
    "                break\n",
    "            # Combine prompt (source) + story (target)\n",
    "            combined = src.strip() + \" \" + tgt.strip()\n",
    "\n",
    "            tokens = combined.split()\n",
    "            truncated = \" \".join(tokens[:max_tokens])\n",
    "            texts.append(truncated)\n",
    "    return texts\n",
    "\n",
    "kaggle_texts = load_kaggle_corpus(split=\"train\", max_samples=5000, max_tokens=1000)\n",
    "corpus_kg = \"\\n\".join(kaggle_texts)\n",
    "print(f\"Loaded {len(kaggle_texts)} samples from 'writingprompts/train' (total chars: {len(corpus_kg)})\")\n",
    "print(\"Example snippet:\\n\", kaggle_texts[0][:300], \"…\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27d8206",
   "metadata": {},
   "source": [
    "## Combine Corpora & Build Markov Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "026eb718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markov model built. Sample sentence:\n",
      "--- In the endless ranks of the street, approached the terminal blinked.\n"
     ]
    }
   ],
   "source": [
    "combined_corpus = \"\\n\".join([corpus_gutenberg, corpus_kg, corpus_gryphe])\n",
    "\n",
    "model = markovify.Text(combined_corpus, state_size=2)\n",
    "\n",
    "print(\"Markov model built. Sample sentence:\")\n",
    "print(model.make_sentence())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cf7164",
   "metadata": {},
   "source": [
    "## Fetching a Trending Topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22abf1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trending topic: Celtics-Knicks: 5 takeaways as New York storms back again to stun Boston - NBA\n"
     ]
    }
   ],
   "source": [
    "def fetch_newsapi_topic():\n",
    "    resp = newsapi.get_top_headlines(country=\"us\", page_size=1)\n",
    "    return resp[\"articles\"][0][\"title\"]\n",
    "\n",
    "def fetch_reddit_topic():\n",
    "    return next(reddit.subreddit(\"all\").hot(limit=1)).title\n",
    "\n",
    "def fetch_pytrends_topic():\n",
    "    return pytrends.trending_searches(pn=\"united_states\")[0]\n",
    "\n",
    "trend = fetch_newsapi_topic()\n",
    "print(\"Trending topic:\", trend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06edb41c",
   "metadata": {},
   "source": [
    "## Generate a Story by Seeding the Markov Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41ac3b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_topic_model(topic, state_size=2):\n",
    "\n",
    "#     sentences = re.split(r'(?<=[\\.\\?\\!])\\s+', combined_corpus)\n",
    "#     keywords = [w.lower() for w in topic.split() if len(w) > 3]\n",
    "#     topic_sentences = [\n",
    "#         s for s in sentences\n",
    "#         if any(kw in s.lower() for kw in keywords)\n",
    "#     ]\n",
    "#     if len(topic_sentences) < 5:\n",
    "#         return None \n",
    "#     return markovify.Text(\"\\n\".join(topic_sentences), state_size=state_size)\n",
    "\n",
    "# topic_model = build_topic_model(trend, state_size=2)\n",
    "\n",
    "# if topic_model:\n",
    "#     combined_model = markovify.combine(\n",
    "#     [topic_model, model], [0.7, 0.3]\n",
    "#     )\n",
    "#     combined_model = combined_model.compile()\n",
    "# else:\n",
    "#     combined_model = model\n",
    "\n",
    "# story_sentences = []\n",
    "# for _ in range(5):\n",
    "#     s = combined_model.make_short_sentence(\n",
    "#         max_chars=100,\n",
    "#         min_chars=50,\n",
    "#         tries=30,\n",
    "#         max_overlap_ratio=0.7,\n",
    "#         max_overlap_total=15\n",
    "#     )\n",
    "#     if s and re.match(r'^[A-Z]', s):\n",
    "#         story_sentences.append(s)\n",
    "\n",
    "# if not story_sentences:\n",
    "#     template = f\"This story is about {trend}. \"\n",
    "#     fallback = model.make_short_sentence(\n",
    "#         max_chars=100, min_chars=50, tries=30\n",
    "#     ) or \"\"\n",
    "#     story_sentences = [template + fallback]\n",
    "\n",
    "# story = \" \".join(story_sentences)\n",
    "# print(\"Generated Story:\\n\", story)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035f4b3a",
   "metadata": {},
   "source": [
    "## Convert Story to Audio (Coqui TTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "919904d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = \"trend_story.wav\"\n",
    "# tts.tts_to_file(text=story, file_path=output_path)\n",
    "# print(\"Saved audio to\", output_path)\n",
    "\n",
    "# ipd.display(ipd.Audio(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f759d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = {\n",
    "#     \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "#     \"topic\": trend,\n",
    "#     \"story\": story,\n",
    "#     \"audio_path\": output_path\n",
    "# }\n",
    "\n",
    "# with open(\"result.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# print(\"Saved result to result.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaac201",
   "metadata": {},
   "source": [
    "## Gradio Interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b444ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trendstory_pipeline(source: str):\n",
    "    try:\n",
    "        if source == \"reddit\":\n",
    "            topic = fetch_reddit_topic()\n",
    "        else:\n",
    "            topic = fetch_newsapi_topic()\n",
    "\n",
    "        seed = topic.split()[0]\n",
    "        sentences = []\n",
    "        for _ in range(5):\n",
    "            try:\n",
    "                s = model.make_sentence_with_start(seed, strict=False)\n",
    "            except ParamError:\n",
    "                s = None\n",
    "            if s:\n",
    "                sentences.append(s)\n",
    "\n",
    "        if not sentences:\n",
    "            for _ in range(5):\n",
    "                s = model.make_short_sentence(\n",
    "                    max_chars=120, min_chars=50,\n",
    "                    tries=30, max_overlap_ratio=0.7,\n",
    "                    max_overlap_total=15\n",
    "                )\n",
    "                if s:\n",
    "                    sentences.append(s)\n",
    "\n",
    "        story = \" \".join(sentences)\n",
    "\n",
    "        audio_path = f\"story_{uuid4().hex}.wav\"\n",
    "        tts.tts_to_file(text=story, file_path=audio_path)\n",
    "\n",
    "        result = {\n",
    "            \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "            \"source\": source,\n",
    "            \"topic\": topic,\n",
    "            \"story\": story,\n",
    "            \"audio_path\": audio_path\n",
    "        }\n",
    "\n",
    "        with open(\"result.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        return topic, story, audio_path, result\n",
    "\n",
    "    except Exception as e:\n",
    "        err = f\"Error: {e}\"\n",
    "        return err, err, None, {\"error\": err}\n",
    "\n",
    "gr.Interface(\n",
    "    fn=trendstory_pipeline,\n",
    "    inputs=gr.Radio([\"newsapi\", \"reddit\"], label=\"Source\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Topic\"),\n",
    "        gr.Textbox(label=\"Story\"),\n",
    "        gr.Audio(label=\"Story Audio\"),\n",
    "        gr.JSON(label=\"Full JSON Output\")\n",
    "    ],\n",
    "    title=\"TrendStory (Markovify + Coqui TTS)\",\n",
    "    description=\"Pick a source to fetch a trend, generate a Markov-based story, play it aloud, and see the JSON output.\"\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8db5746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7860\n",
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
